---
title: "Fitting a simple tvem with numeric output"
author: "John J. Dziak"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Fitting a simple tvem with numeric output}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this example we simulate a longitudinal dataset and fit a simple time-varying coefficient model to it.  

First we call load the tvem library.

```{r}
library(tvem)
```

The tvem library has a function for simulating a dataset.  It is good to start by specifying a random seed.

```{r}
set.seed(123);
the_data <- simulate_tvem_example();
```

When analyzing any dataset, it is important to examine it descriptively first.

```{r}
print(head(the_data));
print(summary(the_data));
```

The dataset is in long form (one row per observation, with multiple observation times for each participant).  There are 300 participants.  Observation time ranges from 0 to 7.  There is a single response variable $y$, and two predictor variables (covariates), $x_1$ and $x_2$.  In the context of an intensive longitudinal study with human participants, these variables might be ratings of different feelings, symptoms or behaviors, reported a few times per day at random times, during seven days following an event (such as the beginning of an intervention, treatment, lifestyle change, etc.).  The values of the covariates and response vary over time within subject.  However, we don't know yet whether their means change systematically over time, whether they are interrelated, or whether this relationship, if it exists, changes over time.

One easy thing to do is to investigate whether and how the response changes over time on average.  This is simply curve fitting, similar to polynomial regression, but can be fit using the TVEM function, in an approach sometimes called `intercept-only TVEM.'  This approach uses a spline function to approximate the change in average $y$ over time.

By default, the tvem function will fit a penalized B-spline, that is, a P-spline following Eilers and Marx (1996).  This approach uses an automatic tuning penalty to choose the level of smoothness versus flexibility of the fitted function.  It is similar, though not identical, to the P-splines used in the Methodology Center's %TVEM SAS macro, which are penalized truncated power splines. 

```{r}
model1 <- tvem(data=the_data,
               formula=y~1,
               id=subject_id,
               time=time);
```
               
You also have the option to turn off the penalty and control the smoothness yourself, by specifying the number of interior knots, here 2.
               
```{r}
model1 <- tvem(data=the_data,
               formula=y~1,
               id=subject_id,
               num_knots=2,
               penalize=FALSE,
               time=time);
```

The implied mean model is $E(y|t) =\beta_0(t)$ Where $t$ is time in days.
After fitting the model, you can print a summary and plot the estimated coefficient.

```{r,fig.width=4,fig.height=4}
print(model1);
plot(model1);
```

The plot shows the estimated coefficient function, and approximate estimates for 95% pointwise confidence intervals (not corrected for potential multiple comparisons) for the value of the function at each time.

We don't provide for random effects in the current version of this package.  Instead, we use a (possibly penalized) form of generalized estimating equations with working independence, and adjust the standard errors for within-subject correlation using a sandwich formula.

It is a very good idea to examine how the covariate means change over time also.  That is, we should fit intercept-only TVEM's for $x_1$ and $x_2, not just $y$.  This gives us an opportunity to explore yet another way to fit a model using the tvem function, by using the select_tvem function to choose the number of knots by an pseudolikelihood equivalent to an AIC or BIC criterion.  "Pseudolikelihood" here means that the information crtierion doesn't take within-subject correlation into account, because we are trying to fit a marginal model agnostic to the exact correlation structure.  

```{r,fig.width=4,fig.height=4}
model2 <- select_tvem(data=the_data,
                    formula = x1~1,
                    id=subject_id,
                    time=time);
print(model2);
plot(model2);
```
                    
It would be good to do the same thing for $x_2$ also.  

After this and other data exploration, we go ahead to fit a nontrivial TVEM model, with covariates.  We allow both $x_1$ and $x_2$ to potentially have ``time-varying effects'' (regression relationships with the response that change over time, that is, a potential interaction between time and the covariate specified without the assumption of linearity).  The implied mean model is $E(y|t, x_1(t),x_2(t)) =\beta_0(t)+\beta_1(t)x_1(t)+\beta2_(t)x_2(t)$ where $t$ is time in days.

```{r,fig.width=4,fig.height=4}
model3 <- tvem(data=the_data,
               formula=y~x1+x2,
               id=subject_id,
               time=time);
print(model3);
plot(model3);
```

Holding $x_1$ and $x_2$ constant, the mean of $y$ seems to decline over time.  The penalty function estimates the relationship as linear for lack of any sign of nonlinearity.  From the results, $x_1$ appears to have an increasingly positive relationship with $y$ over time.  $x_2$ also seems to predict $y$, but the strength of the relationship does not change over time.  So we could fit a similar model, but with $x_2$ having a non-time-varying effect, even though it has time-varying values.

```{r,fig.width=4,fig.height=4}
model4 <- tvem(data=the_data,
               formula=y~x1,
               invar_effect=~x2,
               id=subject_id,
               time=time);
print(model4);
plot(model4);
```

The seeming oscillations in the confidence interval width do not have any particular interpretation;  they are just an accident of the placement of the knots.  The takeaway message is the increasing $\beta_1(t)$ over time, suggesting an increasing association between $x_1$ and $y$, that is, some kind of interaction between $t$ and $x_1$ in predicting $y$.